{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a Decision Tree with PySpark\n",
    "\n",
    "Spark is a powerful, general purpose tool for working with Big Data. Spark transparently handles the distribution of compute tasks across a cluster. This means that operations are fast, but it also allows you to focus on the analysis rather than worry about technical details.\n",
    "\n",
    "### Index \n",
    "1. Little remainder of the characteristics of Spark\n",
    "2. Loading the data\n",
    "3. Data Preparation\n",
    "4. Train/test split\n",
    "5. Build a Decision Tree\n",
    "6. Evaluate the Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType\n",
    "from pyspark.sql import SparkSession            # Import the PySpark module\n",
    "from pyspark.sql.functions import round         # Import the required function\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml.feature import VectorAssembler  # Import the necessary class\n",
    "from pyspark.ml.classification import DecisionTreeClassifier # Decision Tree Classifier "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Characteristics of Spark\n",
    "Spark is currently the most popular technology for processing large quantities of data. Not only is it able to handle enormous data volumes, but it does so very efficiently too!\n",
    "\n",
    "### Components in a Spark Cluster\n",
    "Spark is a distributed computing platform. It achieves efficiency by distributing data and computation across a cluster of computers. A Spark cluster consists of a number of hardware and software components which work together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.7\n"
     ]
    }
   ],
   "source": [
    "# Create SparkSession object\n",
    "spark = SparkSession.builder \\\n",
    "                    .master('local[*]') \\\n",
    "                    .appName('test') \\\n",
    "                    .getOrCreate()\n",
    "\n",
    "# What version of Spark?\n",
    "print(spark.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Loading flights data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data contain 50000 records.\n",
      "+---+---+---+-------+------+---+----+------+--------+-----+\n",
      "|mon|dom|dow|carrier|flight|org|mile|depart|duration|delay|\n",
      "+---+---+---+-------+------+---+----+------+--------+-----+\n",
      "| 11| 20|  6|     US|    19|JFK|2153|  9.48|     351| null|\n",
      "|  0| 22|  2|     UA|  1107|ORD| 316| 16.33|      82|   30|\n",
      "|  2| 20|  4|     UA|   226|SFO| 337|  6.17|      82|   -8|\n",
      "|  9| 13|  1|     AA|   419|ORD|1236| 10.33|     195|   -5|\n",
      "|  4|  2|  5|     AA|   325|ORD| 258|  8.92|      65| null|\n",
      "+---+---+---+-------+------+---+----+------+--------+-----+\n",
      "only showing top 5 rows\n",
      "\n",
      "[('mon', 'int'), ('dom', 'int'), ('dow', 'int'), ('carrier', 'string'), ('flight', 'int'), ('org', 'string'), ('mile', 'int'), ('depart', 'double'), ('duration', 'int'), ('delay', 'int')]\n"
     ]
    }
   ],
   "source": [
    "path = \"/home/danae/Documents/pySparkTraining/files/\"\n",
    "# Read data from CSV file\n",
    "flights = spark.read.csv(path + 'flights.csv',\n",
    "                         sep=',',\n",
    "                         header=True,\n",
    "                         inferSchema=True,\n",
    "                         nullValue='NA')\n",
    "\n",
    "# Get number of records\n",
    "print(\"The data contain %d records.\" % flights.count())\n",
    "\n",
    "# View the first five records\n",
    "flights.show(5)\n",
    "\n",
    "# Check column data types\n",
    "print(flights.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Preparation\n",
    "\n",
    "You previously loaded airline flight data from a CSV file. You're going to develop a model which will predict whether or not a given flight will be delayed.\n",
    "\n",
    "In this exercise you need to trim those data down by:\n",
    "\n",
    "removing an uninformative column and\n",
    "removing rows which do not have information about whether or not a flight was delayed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47022\n"
     ]
    }
   ],
   "source": [
    "# Remove the 'flight' column\n",
    "flights_drop_column = flights.drop('flight')\n",
    "\n",
    "# Number of records with missing 'delay' values\n",
    "flights_drop_column.filter('delay IS NULL').count()\n",
    "\n",
    "# Remove records with missing 'delay' values\n",
    "flights_valid_delay = flights_drop_column.filter('delay IS NOT NULL')\n",
    "\n",
    "# Remove records with missing values in any column and get the number of remaining rows\n",
    "flights_none_missing = flights_valid_delay.dropna()\n",
    "print(flights_none_missing.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Column manipulation\n",
    "\n",
    "The Federal Aviation Administration (FAA) considers a flight to be \"delayed\" when it arrives 15 minutes or more after its scheduled time.\n",
    "\n",
    "The next step of preparing the flight data has two parts:\n",
    "\n",
    "1. convert the units of distance, replacing the mile column with a `kmcolumn`; and\n",
    "2. create a Boolean column indicating whether or not a flight was delayed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+-------+------+---+------+--------+-----+------+-----+\n",
      "|mon|dom|dow|carrier|flight|org|depart|duration|delay|    km|label|\n",
      "+---+---+---+-------+------+---+------+--------+-----+------+-----+\n",
      "| 11| 20|  6|     US|    19|JFK|  9.48|     351| null|3465.0| null|\n",
      "|  0| 22|  2|     UA|  1107|ORD| 16.33|      82|   30| 509.0|    1|\n",
      "|  2| 20|  4|     UA|   226|SFO|  6.17|      82|   -8| 542.0|    0|\n",
      "|  9| 13|  1|     AA|   419|ORD| 10.33|     195|   -5|1989.0|    0|\n",
      "|  4|  2|  5|     AA|   325|ORD|  8.92|      65| null| 415.0| null|\n",
      "+---+---+---+-------+------+---+------+--------+-----+------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Convert 'mile' to 'km' and drop 'mile' column\n",
    "flights_km = flights.withColumn('km', round(flights.mile * 1.60934 , 0)) \\\n",
    "                    .drop('mile')\n",
    "\n",
    "# Create 'label' column indicating whether flight delayed (1) or not (0)\n",
    "flights_km = flights_km.withColumn('label', (flights_km.delay >= 15).cast('integer'))\n",
    "\n",
    "# Check first five records\n",
    "flights_km.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Categorical columns\n",
    "In the flights data there are two columns, carrier and org, which hold categorical data. You need to transform those columns into indexed numerical values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an indexer\n",
    "indexer = StringIndexer(inputCol='carrier', outputCol='carrier_idx')\n",
    "\n",
    "# Indexer identifies categories in the data\n",
    "indexer_model = indexer.fit(flights)\n",
    "\n",
    "# Indexer creates a new column with numeric index values\n",
    "flights_indexed = indexer_model.transform(flights)\n",
    "\n",
    "# Repeat the process for the other categorical feature\n",
    "flights_indexed = StringIndexer(inputCol='org', outputCol='org_idx')\\\n",
    "                                .fit(flights_indexed)\\\n",
    "                                .transform(flights_indexed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step to encoding categorical features is to create a `StringIndexer`. Members of this class are **Estimators** that take a DataFrame with a column of strings and map each unique string to a number. \n",
    "\n",
    "Then, the *Estimator* returns a **Transformer** that takes a DataFrame, attaches the mapping to it as metadata, and returns a new DataFrame with a numeric column corresponding to the string column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------+\n",
      "|carrier|carrier_idx|\n",
      "+-------+-----------+\n",
      "|     UA|        0.0|\n",
      "|     AA|        1.0|\n",
      "|     OO|        2.0|\n",
      "|     WN|        3.0|\n",
      "|     B6|        4.0|\n",
      "+-------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "flights_indexed.select('carrier', 'carrier_idx').distinct().orderBy('carrier_idx').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+\n",
      "|org|org_idx|\n",
      "+---+-------+\n",
      "|ORD|    0.0|\n",
      "|SFO|    1.0|\n",
      "|JFK|    2.0|\n",
      "|LGA|    3.0|\n",
      "|SJC|    4.0|\n",
      "+---+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "flights_indexed.select('org', 'org_idx').distinct().orderBy('org_idx').show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Assembling columns\n",
    "The final stage of data preparation is to consolidate all of the predictor columns into a single column.\n",
    "\n",
    "This has to be done before modeling because every Spark modeling routine expects the data to be in this form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+---+---+-------+---+------+--------+-----+----+-----------+-------+------+-----+\n",
      "|flight|mon|dom|dow|carrier|org|depart|duration|delay|mile|carrier_idx|org_idx|    km|label|\n",
      "+------+---+---+---+-------+---+------+--------+-----+----+-----------+-------+------+-----+\n",
      "|  1107|  0| 22|  2|     UA|ORD| 16.33|      82|   30| 316|        0.0|    0.0| 509.0|    1|\n",
      "|   226|  2| 20|  4|     UA|SFO|  6.17|      82|   -8| 337|        0.0|    1.0| 542.0|    0|\n",
      "|   419|  9| 13|  1|     AA|ORD| 10.33|     195|   -5|1236|        1.0|    0.0|1989.0|    0|\n",
      "|   704|  5|  2|  1|     UA|SFO|  7.98|     102|    2| 550|        0.0|    1.0| 885.0|    0|\n",
      "|   380|  7|  2|  6|     AA|ORD| 10.83|     135|   54| 733|        1.0|    0.0|1180.0|    1|\n",
      "+------+---+---+---+-------+---+------+--------+-----+----+-----------+-------+------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "flights = flights_indexed.join(flights_km, ['flight', 'mon', 'dom', 'dow', 'carrier'\n",
    "                                            , 'org', 'depart', 'duration', 'delay'])\n",
    "flights.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------------+-----+\n",
      "|features                                 |label|\n",
      "+-----------------------------------------+-----+\n",
      "|[0.0,22.0,2.0,0.0,0.0,509.0,16.33,82.0]  |1    |\n",
      "|[2.0,20.0,4.0,0.0,1.0,542.0,6.17,82.0]   |0    |\n",
      "|[9.0,13.0,1.0,1.0,0.0,1989.0,10.33,195.0]|0    |\n",
      "|[5.0,2.0,1.0,0.0,1.0,885.0,7.98,102.0]   |0    |\n",
      "|[7.0,2.0,6.0,1.0,0.0,1180.0,10.83,135.0] |1    |\n",
      "+-----------------------------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "flights = flights.select('mon', 'dom', 'dow', 'carrier_idx', \n",
    "                         'org_idx', 'km', 'depart', 'duration', 'delay', 'label')\n",
    "\n",
    "# Create an assembler object\n",
    "assembler = VectorAssembler(inputCols=[\n",
    "    'mon', 'dom', 'dow', 'carrier_idx', 'org_idx', 'km', 'depart', 'duration'\n",
    "], outputCol='features')\n",
    "\n",
    "# Consolidate predictor columns\n",
    "flights_assembled = assembler.transform(flights)\n",
    "\n",
    "# Check the resulting column\n",
    "flights_assembled.select('features','label').show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree\n",
    "\n",
    "## 4. Train/test split\n",
    "\n",
    "To objectively assess a Machine Learning model you need to be able to test it on an independent set of data. You can't use the same data that you used to train the model: of course the model will perform (relatively) well on those data!\n",
    "\n",
    "You will split the data into two components:\n",
    "\n",
    "- training data (used to train the model) and\n",
    "- testing data (used to test the model).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7980732423121092\n"
     ]
    }
   ],
   "source": [
    "# Split into training and testing sets in a 80:20 ratio\n",
    "flights_train, flights_test = flights_assembled.randomSplit([0.8, 0.2], seed=17)\n",
    "\n",
    "# Check that training set has around 80% of records\n",
    "training_ratio = flights_train.count() / flights.count()\n",
    "print(training_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+-----------+-------+-----+------+--------+-----+-----+--------------------+\n",
      "|mon|dom|dow|carrier_idx|org_idx|   km|depart|duration|delay|label|            features|\n",
      "+---+---+---+-----------+-------+-----+------+--------+-----+-----+--------------------+\n",
      "|  0|  1|  2|        0.0|    0.0|378.0| 21.33|      69|   70|    1|[0.0,1.0,2.0,0.0,...|\n",
      "|  0|  1|  2|        0.0|    0.0|386.0| 13.17|      68|   68|    1|[0.0,1.0,2.0,0.0,...|\n",
      "|  0|  1|  2|        0.0|    0.0|386.0| 21.25|      68|   85|    1|[0.0,1.0,2.0,0.0,...|\n",
      "|  0|  1|  2|        0.0|    0.0|476.0| 13.75|      75|   68|    1|[0.0,1.0,2.0,0.0,...|\n",
      "|  0|  1|  2|        0.0|    0.0|538.0| 22.45|      79|   86|    1|[0.0,1.0,2.0,0.0,...|\n",
      "+---+---+---+-----------+-------+-----+------+--------+-----+-----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "flights_train.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Build a Decision Tree\n",
    "Now that you've split the flights data into training and testing sets, you can use the training set to fit a Decision Tree model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+---------------------------------------+\n",
      "|label|prediction|probability                            |\n",
      "+-----+----------+---------------------------------------+\n",
      "|1    |1.0       |[0.389808712425655,0.6101912875743449] |\n",
      "|1    |1.0       |[0.389808712425655,0.6101912875743449] |\n",
      "|0    |1.0       |[0.3186365751512331,0.6813634248487669]|\n",
      "|1    |1.0       |[0.389808712425655,0.6101912875743449] |\n",
      "|1    |1.0       |[0.389808712425655,0.6101912875743449] |\n",
      "+-----+----------+---------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a classifier object and fit to the training data\n",
    "tree = DecisionTreeClassifier()\n",
    "tree_model = tree.fit(flights_train)\n",
    "\n",
    "# Create predictions for the testing data and take a look at the predictions\n",
    "prediction = tree_model.transform(flights_test)\n",
    "prediction.select('label', 'prediction', 'probability').show(5, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Evaluate the Decision Tree\n",
    "You can assess the quality of your model by evaluating how well it performs on the testing data. Because the model was not trained on these data, this represents an objective assessment of the model.\n",
    "\n",
    "A confusion matrix gives a useful breakdown of predictions versus known values. It has four cells which represent the counts of:\n",
    "\n",
    "- True Negatives (TN) — model predicts negative outcome & known outcome is negative\n",
    "- True Positives (TP) — model predicts positive outcome & known outcome is positive\n",
    "- False Negatives (FN) — model predicts negative outcome but known outcome is positive\n",
    "- False Positives (FP) — model predicts positive outcome but known outcome is negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+-----+\n",
      "|label|prediction|count|\n",
      "+-----+----------+-----+\n",
      "|    1|       0.0| 1243|\n",
      "|    0|       0.0| 2400|\n",
      "|    1|       1.0| 3628|\n",
      "|    0|       1.0| 2224|\n",
      "+-----+----------+-----+\n",
      "\n",
      "0.6348604528699315\n"
     ]
    }
   ],
   "source": [
    "# Create a confusion matrix\n",
    "prediction.groupBy('label', 'prediction').count().show()\n",
    "\n",
    "# Calculate the elements of the confusion matrix\n",
    "TN = prediction.filter('prediction = 0 AND label = prediction').count()\n",
    "TP = prediction.filter('prediction = 1 AND label = prediction').count()\n",
    "FN = prediction.filter('prediction = 0 AND label != prediction').count()\n",
    "FP = prediction.filter('prediction = 1 AND label != prediction').count()\n",
    "\n",
    "# Accuracy measures the proportion of correct predictions\n",
    "accuracy = (TN+TP)/(TN+TP+FN+FP)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Terminate the cluster\n",
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
